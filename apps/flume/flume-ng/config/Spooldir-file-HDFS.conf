server.sources = static_log_source server.channels = hdfs_channelserver.sinks = hdfs_sink
server.sources.static_log_source.type = spooldirserver.sources.static_log_source.spoolDir = /srv/BigData/hadoop/data1/flume_pool/log_to_hdfs/Flume_Encoded/Log_Online_1server.sources.static_log_source.fileSuffix = .COMPLETEDserver.sources.static_log_source.ignorePattern = ^$server.sources.static_log_source.trackerDir = /srv/BigData/hadoop/data2/flume_pool/log_to_hdfs/Log_Online_1/trackerserver.sources.static_log_source.maxBlobLength = 16384server.sources.static_log_source.batchSize = 10000server.sources.static_log_source.inputCharset = UTF-8server.sources.static_log_source.deserializer = LINEserver.sources.static_log_source.deserializer.maxBatchLine = 10server.sources.static_log_source.deserializer.maxLineLength = 102400server.sources.static_log_source.selector.type = replicatingserver.sources.static_log_source.fileHeaderKey = fileserver.sources.static_log_source.fileHeader = falseserver.sources.static_log_source.basenameHeader = trueserver.sources.static_log_source.basenameHeaderKey = basenameserver.sources.static_log_source.deletePolicy = never
server.channels.hdfs_channel.type = fileserver.channels.hdfs_channel.capacity = 100000server.channels.hdfs_channel.write-timeout = 1server.channels.hdfs_channel.transactionCapacity = 10000server.channels.hdfs_channel.maxFileSize = 2146435071server.channels.hdfs_channel.minimumRequiredSpace = 524288000server.channels.hdfs_channel.dataDirs = /srv/BigData/hadoop/data2/filechannel/hdfs_channel/dataDirs,/srv/BigData/hadoop/data1/filechannel/hdfs_channel/dataDirs/srv/BigData/hadoop/data3/filechannel/hdfs_channel/dataDirsserver.channels.hdfs_channel.checkpointDir = /srv/BigData/hadoop/data2/filechannel/hdfs_channel/checkpointserver.channels.hdfs_channel.keep-alive = 10
server.sinks.hdfs_sink.type = hdfsserver.sinks.hdfs_sink.hdfs.inUsePrefix = TMP_server.sinks.hdfs_sink.hdfs.filePrefix = over_%{basename}server.sinks.hdfs_sink.hdfs.fileNameUseTimeStamp = falseserver.sinks.hdfs_sink.hdfs.fileType = DataStreamserver.sinks.hdfs_sink.hdfs.writeFormat = Writableserver.sinks.hdfs_sink.hdfs.callTimeout = 10000server.sinks.hdfs_sink.hdfs.codeC =server.sinks.hdfs_sink.hdfs.round = falseserver.sinks.hdfs_sink.hdfs.roundUnit = secondserver.sinks.hdfs_sink.hdfs.rollCount = 0server.sinks.hdfs_sink.hdfs.rollSize = 0server.sinks.hdfs_sink.hdfs.rollInterval = 0server.sinks.hdfs_sink.hdfs.rollTimerPoolSize = 1server.sinks.hdfs_sink.hdfs.kerberosPrincipal = flumeserver.sinks.hdfs_sink.hdfs.kerberosKeytab = /opt/huawei/Bigdata/FusionInsight/FusionInsight-Flume-1.6.0/flume/conf/flume.keytabserver.sinks.hdfs_sink.hdfs.fileSuffix =server.sinks.hdfs_sink.hdfs.useLocalTimeStamp = trueserver.sinks.hdfs_sink.hdfs.fileCloseByEndEvent = trueserver.sinks.hdfs_sink.hdfs.maxOpenFiles = 5000server.sinks.hdfs_sink.hdfs.minBlockReplicas = 0server.sinks.hdfs_sink.hdfs.idleTimeout = 0server.sinks.hdfs_sink.serializer = TEXTserver.sinks.hdfs_sink.serializer.appendNewline = trueserver.sinks.hdfs_sink.hdfs.roundValue = 1server.sinks.hdfs_sink.hdfs.batchSize = 10000server.sinks.hdfs_sink.hdfs.threadsPoolSize = 1000server.sinks.hdfs_sink.hdfs.path = hdfs://hacluster/flume/zb
server.sinks.hdfs_sink.channel = hdfs_channelserver.sources.static_log_source.channels = hdfs_channel
