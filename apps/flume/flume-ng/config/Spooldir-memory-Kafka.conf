server.sources = static_log_source server.channels = hdfs_channelserver.sinks = kafka_sink
server.sources.static_log_source.type = spooldirserver.sources.static_log_source.spoolDir = /srv/BigData/hadoop/data1/flume_pool/log_to_hdfs/Flume_Encoded/Log_Online_1server.sources.static_log_source.fileSuffix = .COMPLETEDserver.sources.static_log_source.ignorePattern = ^$server.sources.static_log_source.trackerDir = /srv/BigData/hadoop/data2/flume_pool/log_to_hdfs/Log_Online_1/trackerserver.sources.static_log_source.maxBlobLength = 16384server.sources.static_log_source.batchSize = 10000server.sources.static_log_source.inputCharset = UTF-8server.sources.static_log_source.deserializer = LINEserver.sources.static_log_source.deserializer.maxBatchLine = 10server.sources.static_log_source.deserializer.maxLineLength = 102400server.sources.static_log_source.selector.type = replicatingserver.sources.static_log_source.fileHeaderKey = fileserver.sources.static_log_source.fileHeader = falseserver.sources.static_log_source.basenameHeader = trueserver.sources.static_log_source.basenameHeaderKey = basenameserver.sources.static_log_source.deletePolicy = never
server.channels.hdfs_channel.type = memoryserver.channels.hdfs_channel.capacity = 100000server.channels.hdfs_channel.transactionCapacity = 10000
server.sinks.kafka_sink.type = org.apache.flume.sink.kafka.KafkaSinkserver.sinks.kafka_sink.topic = test1server.sinks.kafka_sink.brokerList = 192.168.150.4:21005,192.168.150.5:21005,192.168.150.6:21005server.sinks.kafka_sink.requiredAcks = 1server.sinks.kafka_sink.batchSize = 10000
server.sinks.kafka_sink.channel = hdfs_channelserver.sources.static_log_source.channels = hdfs_channel
